{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88587049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 21:55:55.269 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.269 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.456 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\arhat\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-25 21:55:55.463 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.470 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.472 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.472 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.472 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.472 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.472 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 21:55:55.476 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import logging\n",
    "import sys\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "from collections.abc import Iterable, Iterator\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Type, Union\n",
    "import shutil\n",
    "from pydantic import BaseModel, ConfigDict, model_validator, validate_call\n",
    "\n",
    "from docling.datamodel.base_models import (\n",
    "    ConversionStatus,\n",
    "    DoclingComponentType,\n",
    "    DocumentStream,\n",
    "    ErrorItem,\n",
    "    InputFormat,\n",
    ")\n",
    "from docling.datamodel.document import (\n",
    "    ConversionResult,\n",
    "    InputDocument,\n",
    "    _DocumentConversionInput,\n",
    ")\n",
    "from docling.datamodel.pipeline_options import PipelineOptions\n",
    "from docling.datamodel.settings import (\n",
    "    DEFAULT_PAGE_RANGE,\n",
    "    DocumentLimits,\n",
    "    PageRange,\n",
    "    settings,\n",
    ")\n",
    "from docling.exceptions import ConversionError\n",
    "from docling.pipeline.asr_pipeline import AsrPipeline\n",
    "from docling.pipeline.base_pipeline import BasePipeline\n",
    "from docling.pipeline.simple_pipeline import SimplePipeline\n",
    "from docling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\n",
    "from docling.utils.utils import chunkify\n",
    "\n",
    "import importlib\n",
    "\n",
    "_log = logging.getLogger(__name__)\n",
    "\n",
    "backend_classes = {\n",
    "    'CsvDocumentBackend': 'docling.backend.csv_backend',\n",
    "    'MsWordDocumentBackend': 'docling.backend.msword_backend',\n",
    "    'MsExcelDocumentBackend': 'docling.backend.msexcel_backend',\n",
    "    'MsPowerpointDocumentBackend': 'docling.backend.mspowerpoint_backend',\n",
    "    'AsciiDocBackend': 'docling.backend.asciidoc_backend',\n",
    "    'MarkdownDocumentBackend': 'docling.backend.md_backend',\n",
    "    'HTMLDocumentBackend': 'docling.backend.html_backend',\n",
    "    'DoclingParseV4DocumentBackend': 'docling.backend.docling_parse_v4_backend',\n",
    "    'PatentUsptoDocumentBackend': 'docling.backend.xml.uspto_backend',\n",
    "    'JatsDocumentBackend': 'docling.backend.xml.jats_backend',\n",
    "    'DoclingJSONBackend': 'docling.backend.json.docling_json_backend',\n",
    "    'NoOpBackend': 'docling.backend.noop_backend',\n",
    "    'AbstractDocumentBackend': 'docling.backend.abstract_backend',\n",
    "}\n",
    "\n",
    "globals().update({\n",
    "    name: getattr(importlib.import_module(module), name)\n",
    "    for name, module in backend_classes.items()\n",
    "})\n",
    "\n",
    "class FormatOption(BaseModel):\n",
    "    pipeline_cls: Type[BasePipeline]\n",
    "    pipeline_options: Optional[PipelineOptions] = None\n",
    "    backend: Type[AbstractDocumentBackend]\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def set_defaults_if_needed(self) -> \"FormatOption\":\n",
    "        if self.pipeline_options is None:\n",
    "            self.pipeline_options = self.pipeline_cls.get_default_options()\n",
    "        return self\n",
    "\n",
    "FORMAT_DEFAULTS: dict[InputFormat, tuple[Type[BasePipeline], Type[AbstractDocumentBackend]]] = {\n",
    "    InputFormat.CSV: (SimplePipeline, CsvDocumentBackend),\n",
    "    InputFormat.XLSX: (SimplePipeline, MsExcelDocumentBackend),\n",
    "    InputFormat.DOCX: (SimplePipeline, MsWordDocumentBackend),\n",
    "    InputFormat.PPTX: (SimplePipeline, MsPowerpointDocumentBackend),\n",
    "    InputFormat.MD: (SimplePipeline, MarkdownDocumentBackend),\n",
    "    InputFormat.ASCIIDOC: (SimplePipeline, AsciiDocBackend),\n",
    "    InputFormat.HTML: (SimplePipeline, HTMLDocumentBackend),\n",
    "    InputFormat.XML_USPTO: (SimplePipeline, PatentUsptoDocumentBackend),\n",
    "    InputFormat.XML_JATS: (SimplePipeline, JatsDocumentBackend),\n",
    "    InputFormat.IMAGE: (StandardPdfPipeline, DoclingParseV4DocumentBackend),\n",
    "    InputFormat.PDF: (StandardPdfPipeline, DoclingParseV4DocumentBackend),\n",
    "    InputFormat.JSON_DOCLING: (SimplePipeline, DoclingJSONBackend),\n",
    "    InputFormat.AUDIO: (AsrPipeline, NoOpBackend),\n",
    "}\n",
    "\n",
    "def get_format_option(input_format: InputFormat) -> FormatOption:\n",
    "    try:\n",
    "        pipeline_cls, backend = FORMAT_DEFAULTS[input_format]\n",
    "        return FormatOption(pipeline_cls=pipeline_cls, backend=backend)\n",
    "    except KeyError:\n",
    "        raise RuntimeError(f\"No default options configured for {input_format}\")\n",
    "\n",
    "class DocumentConverter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        allowed_formats: Optional[List[InputFormat]] = None,\n",
    "        format_options: Optional[Dict[InputFormat, FormatOption]] = None,\n",
    "    ):\n",
    "        self.allowed_formats = allowed_formats or list(InputFormat)\n",
    "        self.format_to_options = {\n",
    "            fmt: format_options.get(fmt) if format_options and fmt in format_options else get_format_option(fmt)\n",
    "            for fmt in self.allowed_formats\n",
    "        }\n",
    "        self.initialized_pipelines: Dict[Tuple[Type[BasePipeline], str], BasePipeline] = {}\n",
    "\n",
    "    def get_pipeline_hash(self, pipeline_options: PipelineOptions) -> str:\n",
    "        options_str = str(pipeline_options.model_dump())\n",
    "        return hashlib.md5(options_str.encode(\"utf-8\"), usedforsecurity=False).hexdigest()\n",
    "\n",
    "    def get_or_create_pipeline(self, doc_format: InputFormat) -> Optional[BasePipeline]:\n",
    "        fmt_option = self.format_to_options.get(doc_format)\n",
    "        if not fmt_option or not fmt_option.pipeline_options:\n",
    "            return None\n",
    "\n",
    "        pipeline_cls = fmt_option.pipeline_cls\n",
    "        options_hash = self.get_pipeline_hash(fmt_option.pipeline_options)\n",
    "        key = (pipeline_cls, options_hash)\n",
    "\n",
    "        if key not in self.initialized_pipelines:\n",
    "            self.initialized_pipelines[key] = pipeline_cls(pipeline_options=fmt_option.pipeline_options)\n",
    "\n",
    "        return self.initialized_pipelines[key]\n",
    "\n",
    "    @validate_call(config=ConfigDict(strict=True))\n",
    "    def convert_single(self, source: Union[Path, str, DocumentStream], **kwargs) -> ConversionResult:\n",
    "        return next(self.convert_multiple([source], **kwargs))\n",
    "\n",
    "    @validate_call(config=ConfigDict(strict=True))\n",
    "    def convert_multiple(\n",
    "        self,\n",
    "        source: Iterable[Union[Path, str, DocumentStream]],\n",
    "        headers: Optional[Dict[str, str]] = None,\n",
    "        raises_on_error: bool = True,\n",
    "        max_num_pages: int = sys.maxsize,\n",
    "        max_file_size: int = sys.maxsize,\n",
    "        page_range: PageRange = DEFAULT_PAGE_RANGE,\n",
    "    ) -> Iterator[ConversionResult]:\n",
    "        limits = DocumentLimits(max_num_pages=max_num_pages, max_file_size=max_file_size, page_range=page_range)\n",
    "        conv_input = _DocumentConversionInput(path_or_stream_iterator=source, limits=limits, headers=headers)\n",
    "\n",
    "        for batch in chunkify(conv_input.docs(self.format_to_options), settings.perf.doc_batch_size):\n",
    "            for result in map(partial(self.process_document, raises_on_error=raises_on_error), batch):\n",
    "                yield result\n",
    "\n",
    "    def process_document(self, in_doc: InputDocument, raises_on_error: bool) -> ConversionResult:\n",
    "        if in_doc.format not in self.allowed_formats:\n",
    "            error_msg = f\"Unsupported format: {in_doc.file}\"\n",
    "            if raises_on_error:\n",
    "                raise ConversionError(error_msg)\n",
    "            return ConversionResult(\n",
    "                input=in_doc,\n",
    "                status=ConversionStatus.SKIPPED,\n",
    "                errors=[ErrorItem(component_type=DoclingComponentType.USER_INPUT, module_name=\"\", error_message=error_msg)]\n",
    "            )\n",
    "\n",
    "        pipeline = self.get_or_create_pipeline(in_doc.format)\n",
    "        if not pipeline:\n",
    "            if raises_on_error:\n",
    "                raise ConversionError(f\"No pipeline available for: {in_doc.file}\")\n",
    "            return ConversionResult(input=in_doc, status=ConversionStatus.FAILURE)\n",
    "\n",
    "        return pipeline.execute(in_doc, raises_on_error=raises_on_error)\n",
    "\n",
    "# --- Streamlit UI ---\n",
    "st.set_page_config(page_title=\"Automated Metadata Generation\", layout=\"centered\", page_icon=\"üìÑ\")\n",
    "\n",
    "st.markdown(\"## üìÑ Automated Meta Data Generation\")\n",
    "st.caption(\"Easily convert documents into clean, structured Markdown.\")\n",
    "\n",
    "with st.container():\n",
    "    st.markdown(\"### üì§ Upload Your Document\")\n",
    "    uploaded_file = st.file_uploader(\"Supported formats: PDF, DOCX, XLSX, PPTX, MD, HTML, TXT, etc.\", type=None)\n",
    "\n",
    "if uploaded_file:\n",
    "    file_suffix = Path(uploaded_file.name).suffix.lower()\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=file_suffix) as tmp_file:\n",
    "        tmp_file.write(uploaded_file.read())\n",
    "        tmp_path = Path(tmp_file.name)\n",
    "\n",
    "    if file_suffix == \".txt\":\n",
    "        md_path = tmp_path.with_suffix(\".md\")\n",
    "        shutil.copy(tmp_path, md_path)\n",
    "        tmp_path = md_path\n",
    "\n",
    "    converter = DocumentConverter()\n",
    "\n",
    "    with st.spinner(\"‚öôÔ∏è Converting your document...\"):\n",
    "        try:\n",
    "            result = converter.convert_single(tmp_path)\n",
    "            md = result.document.export_to_markdown()\n",
    "            st.success(\"‚úÖ Conversion successful!\")\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(\"### üìù Markdown Output\")\n",
    "            st.markdown(md, unsafe_allow_html=True)\n",
    "            st.download_button(\"‚¨áÔ∏è Download Markdown File\", md, file_name=\"converted.md\", mime=\"text/markdown\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"‚ùå Error during conversion: `{str(e)}`\")\n",
    "else:\n",
    "    st.info(\"üìé Please upload a document to begin the conversion.\")\n",
    "# cd C:\\Users\\arhat\\OneDrive\\Desktop\\metadata_genai\n",
    "# python -m jupyter nbconvert --to script document_converter_ui.ipynb\n",
    "# streamlit run document_converter_ui.py\n",
    "# the code runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
